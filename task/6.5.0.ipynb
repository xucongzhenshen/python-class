{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dab62f",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[<span style='color:yellow;'>HW: Parkour Athlete Tracking</span>](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9890e8",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [<span style='color:yellow;'>HW: Parkour Athlete Tracking</span>](#toc1_)    \n",
    "  - [Assignment Overview](#toc1_1_)    \n",
    "  - [Learning Objectives](#toc1_2_)    \n",
    "  - [Prerequisites](#toc1_3_)    \n",
    "  - [Required Libraries](#toc1_4_)    \n",
    "  - [Tasks to Complete](#toc1_5_)    \n",
    "    - [Environment Setup (10%)](#toc1_5_1_)    \n",
    "    - [Frame Preprocessing (15%)](#toc1_5_2_)    \n",
    "    - [Model Configuration (15%)](#toc1_5_3_)    \n",
    "    - [Video Configuration (10%)](#toc1_5_4_)    \n",
    "    - [Tracking System Implementation (25%)](#toc1_5_5_)    \n",
    "    - [Video Processing Pipeline (15%)](#toc1_5_6_)    \n",
    "    - [Data Logging (5%)](#toc1_5_7_)    \n",
    "    - [Results Visualization (5%)](#toc1_5_8_)    \n",
    "  - [Deliverables](#toc1_6_)    \n",
    "  - [Video Source](#toc1_7_)    \n",
    "  - [Evaluation Criteria](#toc1_8_)    \n",
    "  - [Tips for Success](#toc1_9_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90383a",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Assignment Overview](#toc0_)\n",
    "In this homework, you will build a complete computer vision pipeline to track parkour athletes in a video using object detection and tracking algorithms. You'll work with OpenCV, YOLOv8, and Python to create a system that can identify, track, and analyze the movement of people performing parkour stunts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977dc1de",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Learning Objectives](#toc0_)\n",
    "- Apply object detection using state-of-the-art YOLO models\n",
    "- Implement tracking algorithms to maintain consistent identification of moving objects\n",
    "- Preprocess video frames to improve detection accuracy\n",
    "- Analyze and visualize tracking results\n",
    "- Work with video I/O operations and data logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406423f",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Prerequisites](#toc0_)\n",
    "- Basic Python programming skills\n",
    "- Familiarity with NumPy for numerical operations\n",
    "- Understanding of computer vision concepts (pixels, frames, bounding boxes)\n",
    "- Prior experience with Jupyter Notebooks (helpful but not required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7530306",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Required Libraries](#toc0_)\n",
    "You'll need to install these libraries:opencv-python\n",
    "numpy\n",
    "matplotlib\n",
    "ultralytics\n",
    "tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e8d4b",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Tasks to Complete](#toc0_)\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Environment Setup (10%)](#toc0_)\n",
    "- Import all required libraries\n",
    "- Verify library installations with a status message\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[Frame Preprocessing (15%)](#toc0_)\n",
    "- Create a function to preprocess video frames for better detection\n",
    "- Implement contrast enhancement using CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "- Convert between color spaces appropriately\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[Model Configuration (15%)](#toc0_)\n",
    "- Load the YOLOv8 Nano model\n",
    "- Configure detection parameters:\n",
    "  - Target class (person)\n",
    "  - Confidence threshold\n",
    "  - IoU (Intersection over Union) threshold\n",
    "- Display a model setup summary\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[Video Configuration (10%)](#toc0_)\n",
    "- Define input/output file paths\n",
    "- Create output directories if they don't exist\n",
    "- Retrieve and display input video properties (resolution, FPS, duration)\n",
    "- Initialize a video writer with appropriate codec settings\n",
    "\n",
    "### <a id='toc1_5_5_'></a>[Tracking System Implementation (25%)](#toc0_)\n",
    "- Design a tracking system that:\n",
    "  - Assigns unique IDs to detected athletes\n",
    "  - Maintains tracking across frames\n",
    "  - Handles temporary disappearances of tracked objects\n",
    "  - Updates tracking data with each new frame\n",
    "- Implement centroid distance calculation for matching objects between frames\n",
    "\n",
    "### <a id='toc1_5_6_'></a>[Video Processing Pipeline (15%)](#toc0_)\n",
    "- Create a multi-stage processing pipeline:\n",
    "  - Read and preprocess frames\n",
    "  - Run object detection on preprocessed frames\n",
    "  - Apply tracking algorithm\n",
    "  - Draw annotations (bounding boxes, IDs, timestamps)\n",
    "  - Save processed frames to output video\n",
    "- Use progress bars to indicate processing status\n",
    "\n",
    "### <a id='toc1_5_7_'></a>[Data Logging (5%)](#toc0_)\n",
    "- Create a CSV file to log tracking data with these fields:\n",
    "  - Frame number\n",
    "  - Timestamp\n",
    "  - Person ID\n",
    "  - Bounding box coordinates (x1, y1, x2, y2)\n",
    "\n",
    "### <a id='toc1_5_8_'></a>[Results Visualization (5%)](#toc0_)\n",
    "- Display a grid of sample frames showing tracking results\n",
    "- Include timestamps for each sample frame\n",
    "- Embed the processed video in your notebook for playback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480e5fdc",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Deliverables](#toc0_)\n",
    "1. A Jupyter Notebook (HTML format) containing all your code and result\n",
    "2. The processed output video\n",
    "3. The tracking data CSV file\n",
    "4. A brief written summary (1-2 paragraphs) describing:\n",
    "   - Any challenges you encountered\n",
    "   - How you improved detection/tracking accuracy\n",
    "   - Possible improvements for future versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7247258",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Video Source](#toc0_)\n",
    "- The parkour video will be released by Prof. Zhang\n",
    "- Students should download the video from our WeChat group and place it in a \"Video\" directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283f320",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[Evaluation Criteria](#toc0_)\n",
    "- Code runs without errors (30%)\n",
    "- Correct implementation of tracking algorithm (25%)\n",
    "- Quality of processed output video (15%)\n",
    "- Proper data logging (10%)\n",
    "- Clear visualization of results (10%)\n",
    "- Code organization and comments (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6636f817",
   "metadata": {},
   "source": [
    "## <a id='toc1_9_'></a>[Tips for Success](#toc0_)\n",
    "- Start with a working detection system before adding tracking\n",
    "- Test with short video clips before processing the full video\n",
    "- Adjust confidence thresholds if you're getting too many false positives/negatives\n",
    "- Use frame preprocessing to handle difficult lighting conditions\n",
    "- Comment your code thoroughly to explain your reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7662a6",
   "metadata": {},
   "source": [
    "Good luck with your parkour tracking system! This assignment will give you practical experience with computer vision techniques that are widely used in video analysis applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
