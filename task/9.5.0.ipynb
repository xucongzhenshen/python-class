{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610d3f38",
   "metadata": {},
   "source": [
    "# <span style='color:gold;'>Task: Synthesize and Analyze an \"Impossible Chord\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb7e954",
   "metadata": {},
   "source": [
    "In this assignment, you will create a musically impossible chord—one that cannot be physically played by humans or produced by any single instrument—using audio signal processing techniques. \n",
    "\n",
    "You will then analyze its properties to understand why it is impossible and how digital synthesis overcomes these limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc506abf",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Generate a chord spanning 8 `octaves` $$(C0 + C4 + C8)$$ and analyze its time-domain, frequency-domain, and perceptual characteristics to explain why it cannot be played by humans or traditional instruments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854356a",
   "metadata": {},
   "source": [
    "## Steps to Complete\n",
    "\n",
    "1. **Define the Impossible Chord**  \n",
    "   - Identify the three constituent notes: C0, C4, and C8.  \n",
    "   - Research and record their frequencies (use the `get_note_frequencies()` function for accuracy).  \n",
    "   - Explain *why* this combination is impossible:  \n",
    "     - Physical limitations of human hands and instruments  \n",
    "     - Perceptual challenges with extreme frequencies  \n",
    "     - Instrument range constraints  \n",
    "\n",
    "2. **Generate Individual Note Signals**  \n",
    "   - Use a 2-second duration and standard sample rate.  \n",
    "   - Create an ADSR envelope for each note (attack=0.05s, decay=0.2s, sustain_level=0.7, release=0.5s) to simulate natural instrument behavior.  \n",
    "   - Generate signals for each note using a piano timbre (via `generate_timbre()`).  \n",
    "\n",
    "3. **Combine the Notes Safely**  \n",
    "   - Use dynamic mixing to combine C4 (as the \"melody\") with C0 + C8 (as the \"chord\") to avoid clipping.  \n",
    "   - Apply a 0.3-second fadeout to eliminate clicks at the end of the signal.  \n",
    "\n",
    "4. **Visualize the Time Domain**  \n",
    "   - Plot a 0.1-second segment of the combined chord.  \n",
    "   - Describe the waveform: How do the three frequencies interact visually? Why is the waveform more complex than a single note?  \n",
    "\n",
    "5. **Analyze Frequency Components**  \n",
    "   - Perform an FFT to identify the dominant frequencies in the chord.  \n",
    "   - Generate a spectrogram to visualize how frequency content changes over time.  \n",
    "   - Verify that all three target frequencies (C0, C4, C8) appear in the analysis.  \n",
    "\n",
    "6. **Evaluate Perception**  \n",
    "   - Play the synthesized chord.  \n",
    "   - Describe what you hear: Which notes are most/least prominent? Why?  \n",
    "   - Connect your observations to the physical limitations of human hearing (e.g., sensitivity to mid-range frequencies vs. extreme lows/highs).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb0317",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "- A Jupyter notebook with your code (modified from the provided template as needed).  \n",
    "- Written explanations for each step (addressing the questions above).  \n",
    "- Plots of the time-domain waveform, FFT results, and spectrogram.  \n",
    "- A 1-2 paragraph conclusion summarizing why this chord is impossible to play naturally and how digital synthesis enables its creation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f6b2d",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "- A single html file with all code organized into logical steps and substeps.  \n",
    "- The script must include comments explaining key operations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ddd82",
   "metadata": {},
   "source": [
    "## Deadline\n",
    "11pm this coming Sunday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4542ab87",
   "metadata": {},
   "source": [
    "## Grading Criteria\n",
    "- Accuracy of signal generation (correct frequencies, envelopes, and mixing).  \n",
    "- Quality of visualizations (clarity, proper labeling, relevant time/frequency ranges).  \n",
    "- Depth of analysis (ability to connect technical properties to musical/physical limitations).  \n",
    "- Correct use of audio processing functions (envelopes, mixing, fadeouts).  \n",
    "\n",
    "Use the provided code template as a starting point, but add your own comments and explanations to demonstrate your understanding of the concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7449fe",
   "metadata": {},
   "source": [
    "# Step 1: 定义不可能的和弦与频率\n",
    "本节将定义C0、C4、C8三个音符，并解释为何这种和弦无法被人类或传统乐器演奏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: 定义C0、C4、C8的频率，并解释不可能的原因\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal\n",
    "import sounddevice as sd\n",
    "def get_note_frequencies():\n",
    "    # 国际标准音高频率\n",
    "    notes = {'C0': 16.35, 'C4': 261.63, 'C8': 4186.01}\n",
    "    return notes\n",
    "notes = get_note_frequencies()\n",
    "print('C0频率:', notes['C0'], 'Hz')\n",
    "print('C4频率:', notes['C4'], 'Hz')\n",
    "print('C8频率:', notes['C8'], 'Hz')\n",
    "# 物理/生理原因解释见markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bd10f",
   "metadata": {},
   "source": [
    "# Step 2: 生成单个音符信号（含ADSR包络和钢琴音色）\n",
    "本节将为每个音符生成2秒的信号，使用ADSR包络和钢琴音色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a594d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: 生成单个音符信号\n",
    "sr = 44100  # 采样率\n",
    "duration = 2.0  # 秒\n",
    "def adsr_envelope(length, sr, attack=0.05, decay=0.2, sustain_level=0.7, release=0.5):\n",
    "    env = np.zeros(length)\n",
    "    a = int(attack * sr)\n",
    "    d = int(decay * sr)\n",
    "    s = int((length/sr - attack - decay - release) * sr)\n",
    "    r = int(release * sr)\n",
    "    # Attack\n",
    "    env[:a] = np.linspace(0, 1, a)\n",
    "    # Decay\n",
    "    env[a:a+d] = np.linspace(1, sustain_level, d)\n",
    "    # Sustain\n",
    "    env[a+d:a+d+s] = sustain_level\n",
    "    # Release\n",
    "    env[a+d+s:] = np.linspace(sustain_level, 0, r)\n",
    "    return env\n",
    "def generate_timbre(freq, sr, duration):\n",
    "    t = np.linspace(0, duration, int(sr*duration), endpoint=False)\n",
    "    # 简单钢琴音色：基频+谐波叠加\n",
    "    signal = np.sin(2*np.pi*freq*t) + 0.5*np.sin(2*np.pi*2*freq*t) + 0.3*np.sin(2*np.pi*3*freq*t)\n",
    "    env = adsr_envelope(len(signal), sr)\n",
    "    return signal * env\n",
    "note_signals = {}\n",
    "for name, freq in notes.items():\n",
    "    note_signals[name] = generate_timbre(freq, sr, duration)\n",
    "    print(f'{name}音符信号已生成')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ae63b",
   "metadata": {},
   "source": [
    "# Step 3: 混合音符并处理淡出\n",
    "本节将动态混合C4（主旋律）与C0、C8（和弦），并在结尾加淡出处理，避免杂音。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3493eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: 混合音符并处理淡出\n",
    "# 动态混合，避免溢出\n",
    "chord = (note_signals['C0'] + note_signals['C8']) / 2\n",
    "melody = note_signals['C4']\n",
    "mix = melody * 0.6 + chord * 0.4\n",
    "# 淡出处理，消除结尾杂音\n",
    "fadeout_len = int(0.3 * sr)\n",
    "fadeout = np.linspace(1, 0, fadeout_len)\n",
    "mix[-fadeout_len:] *= fadeout\n",
    "mix = mix / np.max(np.abs(mix))  # 归一化\n",
    "print('和弦混合与淡出处理完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc35ac75",
   "metadata": {},
   "source": [
    "# Step 4: 时域波形可视化\n",
    "本节将绘制和弦信号的0.1秒片段，观察多频率叠加后的波形复杂性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d273b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: 时域波形可视化\n",
    "plt.figure(figsize=(10,4))\n",
    "segment = mix[:int(0.1*sr)]\n",
    "plt.plot(segment)\n",
    "plt.title('和弦信号的0.1秒时域波形')\n",
    "plt.xlabel('样本点')\n",
    "plt.ylabel('幅值')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# 注释：可见多频率叠加后波形复杂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ce5506",
   "metadata": {},
   "source": [
    "# Step 5: 频域分析（FFT与声谱图）\n",
    "本节将分析和弦的主频成分，并绘制声谱图，验证C0、C4、C8频率均被合成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: 频域分析（FFT与声谱图）\n",
    "# FFT分析\n",
    "fft = np.fft.rfft(mix)\n",
    "freqs = np.fft.rfftfreq(len(mix), 1/sr)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(freqs, np.abs(fft))\n",
    "plt.title('和弦信号的频谱（FFT）')\n",
    "plt.xlabel('频率 (Hz)')\n",
    "plt.ylabel('幅值')\n",
    "plt.xlim(0, 5000)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# 声谱图\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.specgram(mix, NFFT=2048, Fs=sr, noverlap=1024, cmap='plasma')\n",
    "plt.title('和弦信号的声谱图')\n",
    "plt.xlabel('时间 (秒)')\n",
    "plt.ylabel('频率 (Hz)')\n",
    "plt.colorbar(label='强度')\n",
    "plt.ylim(0, 5000)\n",
    "plt.show()\n",
    "# 注释：可见C0、C4、C8频率均被合成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b480b",
   "metadata": {},
   "source": [
    "# Step 6: 播放和弦并听觉评价\n",
    "本节将播放合成和弦，并描述听感。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d40ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: 播放和弦并听觉评价\n",
    "sd.play(mix, sr)\n",
    "sd.wait()\n",
    "# 注释：中频C4最明显，极低C0和极高C8较难分辨，体现人耳频率敏感性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc0850",
   "metadata": {},
   "source": [
    "# Step 7: 总结与心得\n",
    "本节总结为何该和弦无法自然演奏，以及数字合成的优势。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
